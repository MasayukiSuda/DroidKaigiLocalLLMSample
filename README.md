# DroidKaigi Local LLM Sample

## モデルファイルの配置方法

このアプリでは、LLMモデルファイルをアプリ内からダウンロードできます。

### モデルのダウンロード方法

1. アプリを起動
2. 画面上部のダウンロードアイコン（↓）をタップして「モデル管理」画面を開く
3. 使用したいモデルの「ダウンロード」ボタンをタップ
4. ダウンロードが完了するまで待機（進捗バーが表示されます）

### 利用可能なモデル

以下のモデルがダウンロード可能です：

1. **Llama 3.2 3B Instruct Q4_K_M**（推奨）
   - サイズ: 約2.3GB
   - 用途: 高品質と端末負荷のバランスが良い
   - ダウンロード元（参考）: [Hugging Face (bartowski)](https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q4_K_M.gguf)

2. **TinyLlama 1.1B Q4**（軽量モデル）
   - サイズ: 約640MB
   - 用途: 軽量で高速な推論、テスト用

3. **Phi-2 Q4**
   - サイズ: 約1.5GB
   - 用途: Microsoft製の中規模モデル

### 注意事項

- モデルファイルは大容量のため、Wi-Fi環境でのダウンロードを推奨します
- ダウンロードしたモデルはアプリの内部ストレージに保存されます
- ストレージ容量に注意してください（Llama 3.2で約2.3GB、TinyLlamaで約640MB など）
- アプリをアンインストールするとダウンロードしたモデルも削除されます

## Gemini Nano利用について

このアプリでは、Google のオンデバイス AI「Gemini Nano」もテストできます。

### 対応端末

Gemini Nanoは以下の端末でのみ利用可能です：

- **Google Pixel9 シリーズ**
  - Pixel 9、Pixel 9 Pro、Pixel 9 Pro XL、Pixel 9 Pro Fold

### 端末での設定

Gemini Nanoを有効にするには以下の設定が必要です：

1. aicore-experimental Google グループに参加します。

2. Android AICore テスト プログラムにオプトインする


### 実装について

- 現在の実装は実験的なものです
- AICore サービスへの直接アクセスを試行します
- 非対応端末では自動的に無効化されます

## Session Proposal
```
生成AIの実装選択肢は多様化しています。本アプリでは三つの異なるアプローチを一つのCompose アプリに統合し、「AI チャット」「リアルタイム文章要約」「リアルタイム文章校正」機能を通じて、同じプロンプト・同じ端末でベンチマークできます。

実装されているアプローチ：
1. **Gemini Nano (On-Device)**: オンデバイスでの高性能AI
2. **Llama.cpp**: オンデバイスでの量子化LLM実行
3. **LiteRT (.task)**: TensorFlow Liteベースの軽量ランタイム

比較軸は下記の5点です：
①導入工数とビルド手順
②モデルサイズ／RAM 使用量  
③推論レイテンシ
④バッテリー消費
⑤ライセンスと運用

Gemini Nano のオンデバイス高性能とプライバシー保護、llama.cpp のオフライン動作と自由度、LiteRT の軽量性と最適化の可能性を実際のベンチマーク結果で可視化します。

すべてオンデバイスで動作するため、プライバシーが保護され、インターネット接続不要で瞬時に応答が得られます。それぞれのアプローチの特徴を理解することで、用途に応じた最適な選択ができるようになります。

本セッションを通じて、多様なLLM実装アプローチを活用したAndroid アプリ開発の実践的な知識を習得できます。実際のコードと性能データを基に、新たなアプリ開発や既存アプリの進化のきっかけとなることを目指します。
```

## ライセンス

このプロジェクトは MIT License の下で公開されています。詳細は [LICENSE](LICENSE) ファイルをご覧ください。

### 第三者ライブラリ

このプロジェクトには以下の第三者ライブラリが含まれています：

- **llama.cpp** - MIT License
  - Copyright (c) 2023-2025 The ggml authors
  - URL: https://github.com/ggerganov/llama.cpp

### 使用上の注意

- 本サンプルは教育・学習目的で作成されています
- 商用利用時は各ライブラリのライセンス条項を遵守してください
- モデルファイルについては、それぞれの提供元のライセンスに従ってください
