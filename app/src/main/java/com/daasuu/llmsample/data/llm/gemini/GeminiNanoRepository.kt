package com.daasuu.llmsample.data.llm.gemini

import com.daasuu.llmsample.data.benchmark.BenchmarkMode
import com.daasuu.llmsample.data.prompts.CommonPrompts
import com.daasuu.llmsample.domain.LLMRepository
import com.google.ai.edge.aicore.GenerativeAIException
import com.google.ai.edge.aicore.GenerativeModel
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.flow.Flow
import timber.log.Timber
import kotlinx.coroutines.flow.FlowCollector
import kotlinx.coroutines.flow.flow
import kotlinx.coroutines.flow.flowOn
import kotlinx.coroutines.flow.onCompletion
import javax.inject.Inject
import javax.inject.Singleton

@Singleton
class GeminiNanoRepository @Inject constructor(
    private val modelManager: GeminiNanoModelManager
) : LLMRepository {

    override suspend fun initialize() {
        // No-op: ModelManagerãŒé…å»¶åˆæœŸåŒ–ã‚’æ‹…å½“ã™ã‚‹ãŸã‚ã€ã“ã“ã§ã¯ä½•ã‚‚ã—ãªã„
    }

    override suspend fun release() {
        modelManager.releaseModel()
    }

    override suspend fun isAvailable(): Boolean {
        return modelManager.isModelAvailable()
    }

    override suspend fun generateChatResponse(prompt: String): Flow<String> = flow {
        val model = modelManager.getOrCreateModel()
        if (model == null) {
            emit("Error: Gemini Nano not initialized")
            return@flow
        }

        // ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å‡¦ç†
        val finalPrompt = if (BenchmarkMode.isCurrentlyEnabled()) {
            CommonPrompts.buildChatPrompt(prompt)
        } else {
            prompt // æœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼ˆGemini Nanoã®ç‰¹æ€§ã‚’æ´»ã‹ã™ï¼‰
        }

        generateStreamingResponse(model, finalPrompt)
    }.flowOn(Dispatchers.IO)

    override suspend fun summarizeText(text: String): Flow<String> = flow {
        val model = modelManager.getOrCreateModel()
        if (model == null) {
            emit("Error: Gemini Nano not initialized")
            return@flow
        }

        val prompt = if (BenchmarkMode.isCurrentlyEnabled()) {
            CommonPrompts.buildSummarizationPrompt(text)
        } else {
            buildSummarizationPrompt(text) // æœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰: Gemini Nanoå‘ã‘æœ€é©åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        }
        generateStreamingResponse(model, prompt)
    }.flowOn(Dispatchers.IO)

    override suspend fun proofreadText(text: String): Flow<String> = flow {
        val model = modelManager.getOrCreateModel()
        if (model == null) {
            emit("Error: Gemini Nano not initialized")
            return@flow
        }

        val prompt = if (BenchmarkMode.isCurrentlyEnabled()) {
            CommonPrompts.buildProofreadingPrompt(text)
        } else {
            buildProofreadingPrompt(text) // æœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰: Gemini Nanoå‘ã‘æœ€é©åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        }
        generateStreamingResponse(model, prompt)
    }.flowOn(Dispatchers.IO)

    /**
     * ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆ
     * å„ãƒªã‚¯ã‚¨ã‚¹ãƒˆã”ã¨ã«ç‹¬ç«‹ã—ãŸãƒ­ãƒ¼ã‚«ãƒ«çŠ¶æ…‹ã‚’æŒã¤
     */
    private suspend fun FlowCollector<String>.generateStreamingResponse(
        model: GenerativeModel,
        prompt: String
    ) {
        val startTime = System.currentTimeMillis()
        var firstTokenTime = 0L // â† ãƒ­ãƒ¼ã‚«ãƒ«å¤‰æ•°: ãƒªã‚¯ã‚¨ã‚¹ãƒˆã”ã¨ã«ç‹¬ç«‹

        try {
            Timber.d("ğŸš€ Using real Gemini Nano API for: ${prompt.take(50)}...")
            // Use streaming generation for real-time response
            model.generateContentStream(prompt)
                .onCompletion {
                    Timber.d("âœ… Gemini Nano stream completed")
                }
                .collect { response ->
                    response.text?.let { text ->
                        if (firstTokenTime == 0L) {
                            firstTokenTime = System.currentTimeMillis() - startTime
                            Timber.d("âš¡ First token received in ${firstTokenTime}ms")
                        }
                        emit(text)
                    }
                }
        } catch (e: GenerativeAIException) {
            // Handle specific AI generation errors
            Timber.e("âŒ GenerativeAI Error: ${e.message}")
            emit("Error: ${e.message}")
        } catch (e: Exception) {
            Timber.w("âš ï¸ Falling back to mock response due to: ${e.message}")
            e.printStackTrace()
            // Fallback to mock on other errors
            mockGenerate(prompt, startTime)
        }
    }

    private suspend fun FlowCollector<String>.mockGenerate(prompt: String, startTime: Long) {
        Timber.d("ğŸ¤– Using mock response for demonstration")
        var firstTokenTime = 0L // â† ãƒ¢ãƒƒã‚¯ç”¨ã®ãƒ­ãƒ¼ã‚«ãƒ«å¤‰æ•°

        val response = when {
            prompt.contains("è¦ç´„") || prompt.lowercase()
                .contains("summarize") -> "ã€ãƒ¢ãƒƒã‚¯ã€‘ ã“ã¡ã‚‰ã¯ãƒ‡ãƒ¢ç”¨ã®è¦ç´„ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã§ã™ã€‚å®Ÿéš›ã®Gemini Nanoã®ä½¿ç”¨ã«ã¯å¯¾å¿œç«¯æœ«ãŒå¿…è¦ã§ã™ã€‚"

            prompt.contains("æ ¡æ­£") || prompt.lowercase()
                .contains("proofread") -> "ã€ãƒ¢ãƒƒã‚¯ã€‘ ã“ã¡ã‚‰ã¯ãƒ‡ãƒ¢ç”¨ã®æ ¡æ­£ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã§ã™ã€‚å®Ÿéš›ã®Gemini Nanoã®ä½¿ç”¨ã«ã¯å¯¾å¿œç«¯æœ«ãŒå¿…è¦ã§ã™ã€‚"

            else -> "ã€ãƒ¢ãƒƒã‚¯ã€‘ ã“ã¡ã‚‰ã¯ãƒ‡ãƒ¢ç”¨ã®ãƒãƒ£ãƒƒãƒˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ã§ã™ã€‚å®Ÿéš›ã®Gemini Nanoã®ä½¿ç”¨ã«ã¯å¯¾å¿œç«¯æœ«ãŒå¿…è¦ã§ã™ã€‚è©¦ã—ãŸã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: '${
                prompt.take(
                    30
                )
            }...'"
        }

        val tokens = response.split("ã€‚")

        tokens.forEach { token ->
            if (firstTokenTime == 0L) {
                firstTokenTime = System.currentTimeMillis() - startTime
            }
            if (token.isNotEmpty()) {
                emit("$tokenã€‚")
                kotlinx.coroutines.delay(80) // Simulate on-device processing delay
            }
        }
    }

    private fun buildSummarizationPrompt(text: String): String {
        val isJapanese = CommonPrompts.containsJapanese(text)
        if (isJapanese) {
            return "ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ—¥æœ¬èªã§ç°¡æ½”ã«è¦ç´„ã—ã¦ãã ã•ã„:\n\n$text"
        }
        return "Please summarize the following text concisely:\n\n$text"
    }

    private fun buildProofreadingPrompt(text: String): String {
        val cleanText = text.trim().take(1200)
        if (cleanText.isEmpty()) return "ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã§ã™ã€‚"
        return "ä»¥ä¸‹ã®æ—¥æœ¬èªæ–‡ç« ã‚’æ ¡æ­£ã—ã¦ãã ã•ã„ã€‚é–“é•ã„ãŒã‚ã‚Œã°ä¿®æ­£ã—ã€ã‚ˆã‚Šè‡ªç„¶ãªè¡¨ç¾ã«æ”¹å–„ã—ã¦ãã ã•ã„:\n\n$cleanText"
    }
}